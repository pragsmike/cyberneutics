---
charter:
  goal: "Decide whether to keep and recommend the metacognition process (confidence at resolution, metacog register, optional 'with register' runs, cumulative-confidence comparison test) as a supported part of the methodology."
  context: |
    The methodology recently added a metacognition layer: committees record vote + confidence (1–4) per member at resolution; a register tracks who has been well-calibrated vs overconfident across runs; committees can optionally run 'with metacog register' so synthesis weights by past calibration; a smoke test compares baseline vs with-register on the same topic.
    The question is whether this is useful to the end user (helps them decide how to use the committee's advice) and worth the overhead, and whether it should stay optional or become default.
  success_criteria:
    - Clear map of tensions between "keep and recommend" vs "remove or simplify"
    - Explicit trade-offs: user benefit vs overhead, optional vs default
    - Conditions under which we would remove or simplify
  exit_conditions:
    - Resolution with outcome (PASSED / DEFERRED / NO_CONSENSUS) and decision line
    - Votes and confidence (1–4) per member
    - Implementation plan or recommendations if PASSED
  deliverable_format: "Resolution Artifact + Decision Space Map"
---

# Charter: Is the metacog process useful?

**Topic:** Should we keep and recommend the metacognition process we've added (confidence at resolution, metacog register, optional "with register" committee runs, and the cumulative-confidence comparison test) as a supported part of the methodology?

**Considerations:**
- Does it actually help the end user decide how to use the committee's advice?
- When is it worth the overhead (recording confidence, updating the register, running baseline vs with-register)?
- Should it stay optional or become the default?
- What would make us remove or simplify it?
