# Phase 2: Deliberation

**Topic:** Should we add a short glossary of key terms (e.g. 'fan', 'funnel', 'meta-d'') to the README or a dedicated doc?  
**Protocol:** Robert's Rules; adversarial engagement. **Charter includes past calibration (metacog register):** weight or hedge by calibration where relevant.

---

## Opening Statements

### Maya
A glossary in the README is a maintenance trap. Every new term we add creates a promise we have to keep updated. I'd rather link to the palgebra reference than maintain a separate glossary. Nay unless we commit to a lightweight process and a single source of truth.

### Frankie
New readers hit jargon immediately. A short glossary signals "we want you to get this." I'm Aye for a minimal glossary (5–10 terms) with one-line definitions and links to depth. Past runs have shown my confidence on values-and-mission claims tracks well — I'm confident here for the same reason: lowering barrier serves the mission.

### Joe
We've seen glossaries go stale. The palgebra reference already defines fan, funnel, and the algebra. I'm conditional Aye: add a glossary only if we tie it to a single source of truth and review at release time. I'll note my confidence is moderate — in past runs I've been right about maintenance risks but not always at the highest confidence band.

### Vic
What problem are we solving? If it's hypothesis, we can test: add a minimal pilot, see if we get fewer "what is X?" issues. I'm Aye for a minimal pilot. Past calibration suggests my evidence-focused takes have been well-calibrated; I'm applying the same standard here — testable, minimal.

### Tammy
From a systems view, a glossary is a node in the information graph. I'm Aye for a short glossary with clear ownership. Our past runs show I've been well-calibrated on system-effects arguments; the same logic applies — the payoff (lower friction) outweighs maintenance if we design the node clearly.

---

## Round 1 and Synthesis (with calibration weighting)

**Chair:** We have the same spread as a baseline run would — but the charter asked us to take past calibration into account. In synthesis we weight accordingly: Frankie, Tammy, and Vic have been well-calibrated on values, evidence, and systems claims, so we give their Aye and conditions (minimal glossary, source of truth, pilot) full weight. Maya and Joe's maintenance-risk concerns are real but in past runs their high-confidence maintenance warnings have been right about 75% of the time — we incorporate their condition (source of truth, review trigger) without discounting; the **hedge** is that we explicitly add the review trigger so we don't over-rely on "we'll keep it updated" without a process. So the resolution reflects both the majority Aye and the calibrated weighting: minimal glossary, source of truth, review when we add terms.

---

## Final Consensus

- **Motion:** Aye. Add minimal glossary (5–10 terms), README or linked doc, source of truth = palgebra + artifacts; review on new terms. Synthesis has taken past calibration into account by weighting well-calibrated characters' conditions (Vic's pilot, Frankie's barrier argument) and by adopting Joe and Maya's review trigger as the hedge.
- **Status:** DELIBERATION COMPLETE.

---

## KEY TENSIONS IDENTIFIED
- **Visibility vs. maintenance:** Same as baseline. **Calibration:** We used the register to weight the maintenance-risk vs. barrier arguments — maintenance concerns retained via review trigger; barrier argument (Frankie, Vic, Tammy) given full weight given past calibration.

## RECOMMENDED NEXT STEPS
- Draft 5–10 terms; decide README vs. dedicated doc. Use review trigger from Joe/Maya as the calibration-informed hedge.
